{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/neesham/xgboost-v-s-lightgbm?scriptVersionId=120271689\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"3edcddba","metadata":{"papermill":{"duration":0.005892,"end_time":"2023-02-25T11:13:40.232924","exception":false,"start_time":"2023-02-25T11:13:40.227032","status":"completed"},"tags":[]},"source":["# In this notebook we will compare two Ultimate ML algorithms.\n","\n","![image](https://res.cloudinary.com/hire-easy/image/upload/v1676710215/decision-trees_gfekyp.png)\n","\n","### XGBoost and LightGBM\n","\n","# Ready? Let's go!\n","\n"]},{"cell_type":"markdown","id":"3a4ed55d","metadata":{"papermill":{"duration":0.004658,"end_time":"2023-02-25T11:13:40.242516","exception":false,"start_time":"2023-02-25T11:13:40.237858","status":"completed"},"tags":[]},"source":["# Set Up"]},{"cell_type":"code","execution_count":1,"id":"4c86c0d9","metadata":{"execution":{"iopub.execute_input":"2023-02-25T11:13:40.254138Z","iopub.status.busy":"2023-02-25T11:13:40.253446Z","iopub.status.idle":"2023-02-25T11:13:41.569411Z","shell.execute_reply":"2023-02-25T11:13:41.567647Z"},"papermill":{"duration":1.325383,"end_time":"2023-02-25T11:13:41.572577","exception":false,"start_time":"2023-02-25T11:13:40.247194","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","from time import time\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import mean_absolute_error"]},{"cell_type":"markdown","id":"bf918cbf","metadata":{"papermill":{"duration":0.004417,"end_time":"2023-02-25T11:13:41.581767","exception":false,"start_time":"2023-02-25T11:13:41.57735","status":"completed"},"tags":[]},"source":["# Pre-Processing the Data (Melbourn Housing)."]},{"cell_type":"code","execution_count":2,"id":"ec68fe07","metadata":{"execution":{"iopub.execute_input":"2023-02-25T11:13:41.593186Z","iopub.status.busy":"2023-02-25T11:13:41.592755Z","iopub.status.idle":"2023-02-25T11:13:41.856032Z","shell.execute_reply":"2023-02-25T11:13:41.854816Z"},"papermill":{"duration":0.272672,"end_time":"2023-02-25T11:13:41.859068","exception":false,"start_time":"2023-02-25T11:13:41.586396","status":"completed"},"tags":[]},"outputs":[],"source":["# Read the data\n","X = pd.read_csv('../input/train.csv', index_col='Id')\n","\n","X_test_full = pd.read_csv('../input/test.csv', index_col='Id')\n","\n","# Remove rows with missing target, separate target from predictors\n","X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n","y = X.SalePrice              \n","X.drop(['SalePrice'], axis=1, inplace=True)\n","\n","# Break off validation set from training data\n","X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n","                                                                random_state=0)\n","\n","# \"Cardinality\" means the number of unique values in a column\n","# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n","low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n","                        X_train_full[cname].dtype == \"object\"]\n","\n","# Select numeric columns\n","numeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n","\n","# Keep selected columns only\n","my_cols = low_cardinality_cols + numeric_cols\n","X_train = X_train_full[my_cols].copy()\n","X_valid = X_valid_full[my_cols].copy()\n","X_test = X_test_full[my_cols].copy()\n","\n","# One-hot encode the data (to shorten the code, we use pandas)\n","X_train = pd.get_dummies(X_train)\n","X_valid = pd.get_dummies(X_valid)\n","X_test = pd.get_dummies(X_test)\n","X_train, X_valid = X_train.align(X_valid, join='left', axis=1)\n","X_train, X_test = X_train.align(X_test, join='left', axis=1)"]},{"cell_type":"markdown","id":"fab41d70","metadata":{"papermill":{"duration":0.004627,"end_time":"2023-02-25T11:13:41.868698","exception":false,"start_time":"2023-02-25T11:13:41.864071","status":"completed"},"tags":[]},"source":["## Similarity between XGBoost and LightGBM\n","\n","1. Both are open-source gradient boosting frameworks that use decision trees for supervised learning tasks.\n","\n","2. Both frameworks use similar boosting algorithms that combine multiple weak learners to create a strong learner.\n","\n","3. Both frameworks allow for parallel processing and can handle large datasets.\n","\n","4. Both frameworks offer a wide range of hyperparameters that can be tuned to optimize performance.\n","\n","5. Both frameworks have gained popularity in the machine learning community and are widely used in industry and academia."]},{"cell_type":"markdown","id":"40bedd61","metadata":{"papermill":{"duration":0.004531,"end_time":"2023-02-25T11:13:41.878123","exception":false,"start_time":"2023-02-25T11:13:41.873592","status":"completed"},"tags":[]},"source":["## Difference between XGBoost and LightGBM\n","\n","1. **Performance**: LightGBM is generally faster than XGBoost because it uses a histogram-based approach to binning continuous features, which can reduce the number of operations required to build trees. LightGBM can also handle larger datasets more efficiently than XGBoost.\n","\n","2. **Memory usage**: LightGBM uses less memory than XGBoost because it only stores non-zero values in the histograms, while XGBoost stores all the values. This can be an important consideration when dealing with large datasets.\n","\n","3. **Tree-building strategy**: LightGBM uses a leaf-wise approach to building trees, while XGBoost uses a depth-wise approach. The leaf-wise approach can lead to more complex trees, but can also lead to overfitting if not carefully tuned. The depth-wise approach builds simpler trees but can be more computationally expensive.\n","\n","4. **Tuning parameters**: Both LightGBM and XGBoost have many tuning parameters, but the default values for LightGBM tend to be more conservative, leading to better out-of-the-box performance."]},{"cell_type":"markdown","id":"b65c848a","metadata":{"papermill":{"duration":0.00445,"end_time":"2023-02-25T11:13:41.887378","exception":false,"start_time":"2023-02-25T11:13:41.882928","status":"completed"},"tags":[]},"source":["> Thats enough for the theory let's move to the coding part."]},{"cell_type":"markdown","id":"d62af0dc","metadata":{"papermill":{"duration":0.004499,"end_time":"2023-02-25T11:13:41.896846","exception":false,"start_time":"2023-02-25T11:13:41.892347","status":"completed"},"tags":[]},"source":["# The XGBoost"]},{"cell_type":"code","execution_count":3,"id":"a0f359e1","metadata":{"execution":{"iopub.execute_input":"2023-02-25T11:13:41.908102Z","iopub.status.busy":"2023-02-25T11:13:41.907681Z","iopub.status.idle":"2023-02-25T11:13:45.013558Z","shell.execute_reply":"2023-02-25T11:13:45.012528Z"},"papermill":{"duration":3.116279,"end_time":"2023-02-25T11:13:45.017837","exception":false,"start_time":"2023-02-25T11:13:41.901558","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Execution Time:  2.9560747146606445\n","Mean absolute error is:  16802.965325342466\n","Accuracy is:  84.67858042263228\n"]}],"source":["from xgboost import XGBRegressor\n","\n","# Set the number of threads to use for training\n","num_threads = 3\n","\n","# Define the model\n","model1 = XGBRegressor(n_estimators=1000, learning_rate=0.05, nthread=num_threads)\n","\n","t0 = time()\n","\n","# Fit the model\n","model1.fit(X_train, y_train,early_stopping_rounds=5,eval_set=[(X_valid, y_valid)],\n","             verbose=False)\n","\n","print(\"Execution Time: \", time() - t0)\n","\n","# Get predictions\n","predictions = model1.predict(X_valid)\n","\n","# Calculate MAE\n","mae_2 = mean_absolute_error(y_valid, predictions)\n","\n","print(\"Mean absolute error is: \", mae_2)\n","\n","# Accuracy\n","print(\"Accuracy is: \", (model1.score(X_valid, y_valid)) * 100)"]},{"cell_type":"markdown","id":"364c7352","metadata":{"papermill":{"duration":0.005312,"end_time":"2023-02-25T11:13:45.02929","exception":false,"start_time":"2023-02-25T11:13:45.023978","status":"completed"},"tags":[]},"source":["# Tuning the hyperparameters"]},{"cell_type":"code","execution_count":4,"id":"9c545584","metadata":{"execution":{"iopub.execute_input":"2023-02-25T11:13:45.041112Z","iopub.status.busy":"2023-02-25T11:13:45.040393Z","iopub.status.idle":"2023-02-25T11:20:25.604513Z","shell.execute_reply":"2023-02-25T11:20:25.603056Z"},"papermill":{"duration":400.575573,"end_time":"2023-02-25T11:20:25.609637","exception":false,"start_time":"2023-02-25T11:13:45.034064","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Execution Time:  400.55134749412537\n","Best hyperparameters:  {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000}\n"]}],"source":["# Define the model\n","model1 = XGBRegressor()\n","\n","\n","# Define the grid of hyperparameters to search\n","params = {\n","    \"n_estimators\": [700, 1000, 1200],\n","    \"max_depth\": [5, 7, 9],\n","    \"learning_rate\": [0.01, 0.05, 0.001],\n","}\n","\n","t0 = time()\n","\n","# Create the grid search object\n","grid = GridSearchCV(model1, params, cv=2)\n","\n","# Fit the model\n","grid.fit(X_train, y_train)\n","\n","print(\"Execution Time: \", time() - t0)\n","\n","# Print the best hyperparameters\n","print(\"Best hyperparameters: \", grid.best_params_)"]},{"cell_type":"markdown","id":"d535a703","metadata":{"papermill":{"duration":0.006001,"end_time":"2023-02-25T11:20:25.621","exception":false,"start_time":"2023-02-25T11:20:25.614999","status":"completed"},"tags":[]},"source":["# The LightGBM"]},{"cell_type":"code","execution_count":5,"id":"9095ec57","metadata":{"execution":{"iopub.execute_input":"2023-02-25T11:20:25.634075Z","iopub.status.busy":"2023-02-25T11:20:25.632298Z","iopub.status.idle":"2023-02-25T11:20:34.85408Z","shell.execute_reply":"2023-02-25T11:20:34.852005Z"},"papermill":{"duration":9.232538,"end_time":"2023-02-25T11:20:34.858512","exception":false,"start_time":"2023-02-25T11:20:25.625974","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<style type='text/css'>\n",".datatable table.frame { margin-bottom: 0; }\n",".datatable table.frame thead { border-bottom: none; }\n",".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",".datatable .bool    { background: #DDDD99; }\n",".datatable .object  { background: #565656; }\n",".datatable .int     { background: #5D9E5D; }\n",".datatable .float   { background: #4040CC; }\n",".datatable .str     { background: #CC4040; }\n",".datatable .time    { background: #40CC40; }\n",".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",".datatable .frame tbody td { text-align: left; }\n",".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",".datatable th:nth-child(2) { padding-left: 12px; }\n",".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",".datatable .sp {  opacity: 0.25;}\n",".datatable .footer { font-size: 9px; }\n",".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] num_threads is set with nthread=3, will be overridden by n_jobs=-1. Current value: num_threads=-1\n","Execution Time:  7.691295385360718\n","Mean absolute error is:  17259.09657799767\n","Accuracy is:  87.6791254297951\n"]}],"source":["import lightgbm as lgb \n","\n","# Set the number of threads to use for training\n","num_threads = 3\n","\n","# Define the model\n","model2 = lgb.LGBMRegressor(n_estimators = 1000, learning_rate = 0.05, nthread=num_threads)\n","\n","t0 = time()\n","\n","# Fit the model\n","model2.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose = False)\n","\n","print(\"Execution Time: \", time() - t0)\n","\n","# Get predictions\n","predictions = model2.predict(X_valid)\n","\n","# Calculate MAE\n","mae_2 = mean_absolute_error(y_valid, predictions)\n","\n","print(\"Mean absolute error is: \", mae_2)\n","\n","# Accuracy\n","print(\"Accuracy is: \", (model2.score(X_valid, y_valid)) * 100)"]},{"cell_type":"markdown","id":"0cc9ce6b","metadata":{"papermill":{"duration":0.004981,"end_time":"2023-02-25T11:20:34.86917","exception":false,"start_time":"2023-02-25T11:20:34.864189","status":"completed"},"tags":[]},"source":["# Tuning the hyperparameters"]},{"cell_type":"code","execution_count":6,"id":"4ecae0b6","metadata":{"execution":{"iopub.execute_input":"2023-02-25T11:20:34.881469Z","iopub.status.busy":"2023-02-25T11:20:34.881003Z","iopub.status.idle":"2023-02-25T11:22:17.748812Z","shell.execute_reply":"2023-02-25T11:22:17.747223Z"},"papermill":{"duration":102.881599,"end_time":"2023-02-25T11:22:17.755956","exception":false,"start_time":"2023-02-25T11:20:34.874357","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Execution Time:  102.8579957485199\n","Best hyperparameters:  {'learning_rate': 0.01, 'n_estimators': 1200, 'num_leaves': 5}\n"]}],"source":["# Define the model\n","model2 = lgb.LGBMRegressor()\n","\n","# Define the grid of hyperparameters to search\n","params = {\n","    \"n_estimators\": [700, 1000, 1200],\n","    \"num_leaves\": [5, 7, 9],\n","    \"learning_rate\": [0.01, 0.05, 0.001],\n","}\n","\n","t0 = time()\n","\n","# Create the grid search object\n","grid = GridSearchCV(model2, params, cv=2)\n","\n","# Fit the model\n","grid.fit(X_train, y_train)\n","\n","print(\"Execution Time: \", time() - t0)\n","\n","# Print the best hyperparameters\n","print(\"Best hyperparameters: \", grid.best_params_)"]},{"cell_type":"markdown","id":"4b0a8337","metadata":{"papermill":{"duration":0.005004,"end_time":"2023-02-25T11:22:17.7662","exception":false,"start_time":"2023-02-25T11:22:17.761196","status":"completed"},"tags":[]},"source":["# Playing with CV"]},{"cell_type":"code","execution_count":7,"id":"a0f04bd3","metadata":{"execution":{"iopub.execute_input":"2023-02-25T11:22:17.778313Z","iopub.status.busy":"2023-02-25T11:22:17.777923Z","iopub.status.idle":"2023-02-25T11:22:22.531483Z","shell.execute_reply":"2023-02-25T11:22:22.529892Z"},"papermill":{"duration":4.763837,"end_time":"2023-02-25T11:22:22.535214","exception":false,"start_time":"2023-02-25T11:22:17.771377","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Scores of XGBoost are:  0.2552202697364413 0.6775487414440469 0.724680272574131 0.7528381976452179 0.8291269183275427\n","Scores of lightGBM are:  0.6625301846164433 0.6926794510430847 0.7558711467543416 0.81287774953039 0.8576677489210873\n"]}],"source":["from sklearn.model_selection import cross_val_score\n","\n","scores_of_XGBoost = cross_val_score(model1, X_valid, y_valid, cv = 5)\n","\n","scores_of_lightGBM = cross_val_score(model2, X_valid, y_valid, cv = 5)\n","\n","scores_of_XGBoost.sort()\n","scores_of_lightGBM.sort()\n","\n","print(\"Scores of XGBoost are: \", *scores_of_XGBoost)\n","print(\"Scores of lightGBM are: \", *scores_of_lightGBM)"]},{"cell_type":"markdown","id":"2418e029","metadata":{"papermill":{"duration":0.00558,"end_time":"2023-02-25T11:22:22.546898","exception":false,"start_time":"2023-02-25T11:22:22.541318","status":"completed"},"tags":[]},"source":["# Conclusion\n","\n","So, both the algorithms performed really great.  Both the algorithms have approximately the same accuracy. But one thing that makes lightGBM notorious is its speed and it clearly outperforms XGBoost in terms of speed.\n","\n","Thanks for reading and if you found this notebook helpful then please smash that upvote button. Also comment down your favorite feature about XGBoost and lightGBM."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":534.742793,"end_time":"2023-02-25T11:22:23.478501","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-02-25T11:13:28.735708","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}